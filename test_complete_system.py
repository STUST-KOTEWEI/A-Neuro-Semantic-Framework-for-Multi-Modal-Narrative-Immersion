"""
å…¨é¢æ¸¬è©¦å¤šæ„Ÿå®˜ç³»çµ± - åŒ…å«æ™ºèƒ½è¡¨æƒ…åµæ¸¬ã€ä¸»é¡Œæ¨è–¦ã€åœ–ç‰‡é¡¯ç¤º
"""
import requests
import json
import time

API_BASE = "http://localhost:8010"

def test_emotion_detection():
    """æ¸¬è©¦è¡¨æƒ…åµæ¸¬ï¼ˆæ™ºèƒ½å‹•æ…‹åµæ¸¬ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ­ æ¸¬è©¦ 1: è¡¨æƒ…åµæ¸¬ï¼ˆå‹•æ…‹æ™ºèƒ½ï¼‰")
    print("="*60)
    
    # æ¸¬è©¦å¤šæ¬¡ï¼Œé©—è­‰è¡¨æƒ…åµæ¸¬æ˜¯å¦æœƒå‹•æ…‹è®ŠåŒ–
    for i in range(3):
        print(f"\nç¬¬ {i+1} æ¬¡åµæ¸¬:")
        response = requests.post(
            f"{API_BASE}/api/detect-emotion",
            json={"image_base64": f"test_image_{i}"}
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"  âœ… ä¸»è¦æƒ…ç·’: {result['primary_emotion']}")
            print(f"  ğŸ“Š å¼·åº¦: {result['intensity']:.2%}")
            print(f"  ğŸ¯ æ¬¡è¦æƒ…ç·’: {result.get('secondary_emotions', [])}")
            print(f"  ğŸ¤– AIå‚™è¨»: {result.get('ai_note', 'N/A')}")
            print(f"  â° æ™‚é–“æˆ³: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(result['timestamp']))}")
        else:
            print(f"  âŒ å¤±æ•—: {response.status_code} - {response.text}")
        
        time.sleep(1)  # é–“éš”1ç§’

def test_complete_generation():
    """æ¸¬è©¦å®Œæ•´ç”Ÿæˆæµç¨‹ï¼ˆæƒ…ç·’ + RAG + AIæ¨è–¦ï¼‰"""
    print("\n" + "="*60)
    print("ğŸš€ æ¸¬è©¦ 2: å®Œæ•´ç”Ÿæˆæµç¨‹ï¼ˆæƒ…ç·’åµæ¸¬ + RAG + AIæ¨è–¦ï¼‰")
    print("="*60)
    
    response = requests.post(
        f"{API_BASE}/api/generate-complete",
        json={
            "camera_image_base64": "test_camera_image",
            "query": "æœªä¾†ç§‘æŠ€èˆ‡äººå·¥æ™ºæ…§",
            "total_count": 1
        }
    )
    
    if response.status_code == 410:
        print("â„¹ï¸ å…§å®¹ç”Ÿæˆç«¯é»å·²åœç”¨ï¼Œæ”¹ç”¨ RAG ä»£è¡¨åœ–æœå°‹ APIã€‚")
        s = requests.get(f"{API_BASE}/data/rag-images/search", params={"q": "æœªä¾†ç§‘æŠ€èˆ‡äººå·¥æ™ºæ…§", "top_k": 1})
        if s.status_code == 200:
            data = s.json()
            if data.get('count', 0) > 0:
                first = data['data'][0]
                print(f"âœ… å–å¾—ä»£è¡¨åœ–: {first.get('image_url','N/A')}")
            else:
                print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç›¸é—œä»£è¡¨åœ–ï¼Œè«‹å…ˆå»ºç«‹ RAG è³‡æ–™åº«ã€‚")
        else:
            print(f"âŒ RAG æœå°‹å¤±æ•—: {s.status_code} - {s.text}")
    elif response.status_code == 200:
        result = response.json()
        
        print("\nğŸ“Š æƒ…ç·’åˆ†æçµæœ:")
        print(f"  ä¸»è¦æƒ…ç·’: {result['emotion']['primary_emotion']}")
        print(f"  å¼·åº¦: {result['emotion']['intensity']:.2%}")
        
        print("\nğŸ–¼ï¸ åœ–åƒç”Ÿæˆçµ±è¨ˆ:")
        stats = result['statistics']
        print(f"  ç¸½åœ–ç‰‡æ•¸: {stats['total_images']}")
        print(f"  RAG åœ–ç‰‡: {stats['rag_images']}")
        print(f"  Gemini åœ–ç‰‡: {stats['gemini_images']}")
        
        print("\nğŸ¤– AI æ™ºèƒ½åˆ†æ:")
        ai = result.get('ai_analysis', {})
        print(f"  åµæ¸¬æƒ…ç·’: {ai.get('emotion_detected', 'N/A')}")
        print(f"  ä¿¡å¿ƒåº¦: {ai.get('confidence', 0):.2%}")
        print(f"  AIå‚™è¨»: {ai.get('ai_note', 'N/A')}")
        
        theme_rec = ai.get('theme_recommendation', {})
        if theme_rec:
            print(f"\nğŸ¨ ä¸»é¡Œæ¨è–¦:")
            print(f"  å»ºè­°ä¸»é¡Œ: {', '.join(theme_rec.get('themes', []))}")
            print(f"  èªªæ˜: {theme_rec.get('description', 'N/A')}")
            print(f"  è‰²å½©: {', '.join(theme_rec.get('colors', []))}")
            print(f"  éŸ³æ¨‚é¢¨æ ¼: {theme_rec.get('music_genre', 'N/A')}")
        
        print(f"\nä¸‹ä¸€æ­¥: {ai.get('next_action', 'N/A')}")
        
        print("\nğŸ“· åœ–åƒç¯„ä¾‹ (å‰5å¼µ):")
        for i, img in enumerate(result['all_images'][:5], 1):
            print(f"  {i}. {img['caption']}")
            print(f"     ä¾†æº: {img['source']}")
            print(f"     URL: {img['url'][:80]}...")
            if 'ai_matched' in img:
                print(f"     AIåŒ¹é…: âœ…")
            if 'theme' in img:
                print(f"     ä¸»é¡Œ: {img.get('theme', 'N/A')} | åœ°å€: {img.get('region', 'N/A')} | èªè¨€: {img.get('language', 'N/A')}")
        
    else:
        print(f"âŒ å¤±æ•—: {response.status_code} - {response.text}")

def test_tts():
    """æ¸¬è©¦ TTSï¼ˆæ–‡å­—è½‰èªéŸ³ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ”Š æ¸¬è©¦ 3: æ–‡å­—è½‰èªéŸ³ (TTS)")
    print("="*60)
    
    response = requests.post(
        f"{API_BASE}/api/tts",
        json={
            "text": "æ­¡è¿ä½¿ç”¨å¤šæ„Ÿå®˜æ²‰æµ¸å¼é–±è®€å™¨ï¼Œè®“AIå¹«ä½ æ¢ç´¢æœªä¾†ä¸–ç•Œï¼",
            "voice": "alloy",
            "emotion": "excited"
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        print(f"  âœ… TTS ç”ŸæˆæˆåŠŸ")
        print(f"  å¼•æ“: {result.get('engine', 'N/A')}")
        print(f"  ç‹€æ…‹: {result.get('status', 'N/A')}")
        if 'audio_url' in result:
            print(f"  éŸ³è¨Š URL: {result['audio_url']}")
        if 'audio_base64' in result:
            print(f"  Base64 é•·åº¦: {len(result['audio_base64'])} å­—å…ƒ")
    else:
        print(f"  âŒ å¤±æ•—: {response.status_code} - {response.text}")

def test_device_broadcast():
    """æ¸¬è©¦è¨­å‚™å»£æ’­"""
    print("\n" + "="*60)
    print("ğŸ“¡ æ¸¬è©¦ 4: è¨­å‚™å»£æ’­")
    print("="*60)
    
    response = requests.post(
        f"{API_BASE}/api/broadcast-to-devices",
        json={
            "emotion": "happy",
            "intensity": 0.85,
            "devices": ["apple_watch", "rayban_meta", "bhaptics"],
            "content": {
                "text": "æ¸¬è©¦å»£æ’­å…§å®¹",
                "images": ["https://example.com/img1.jpg"]
            }
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        if result.get('placeholder'):
            print("â„¹ï¸ å¤šæ„Ÿå®˜è¨­å‚™ç‚ºåˆä½œé ç•™å€ï¼Œæœªå¯¦éš›å»£æ’­ã€‚")
        else:
            print(f"  âœ… å»£æ’­æˆåŠŸ")
            print(f"  æƒ…ç·’: {result.get('emotion','N/A')}")
            print(f"  å¼·åº¦: {result.get('intensity','N/A')}")
    else:
        print(f"  âŒ å¤±æ•—: {response.status_code} - {response.text}")

def test_rag_images():
    """æ¸¬è©¦ RAG åœ–åƒè³‡æ–™åº«"""
    print("\n" + "="*60)
    print("ğŸ–¼ï¸ æ¸¬è©¦ 5: RAG åœ–åƒè³‡æ–™åº«ï¼ˆå¤šä¸»é¡Œã€å¤šèªè¨€ã€å¤šåœ°å€ï¼‰")
    print("="*60)
    
    response = requests.get(f"{API_BASE}/data/rag-images")
    
    if response.status_code == 200:
        result = response.json()
        print(f"  âœ… è³‡æ–™åº«è®€å–æˆåŠŸ")
        print(f"  ç¸½åœ–ç‰‡æ•¸: {len(result['data'])}")
        
        print("\n  åœ–ç‰‡ä¸»é¡Œåˆ†å¸ƒ:")
        themes = {}
        emotions = {}
        regions = {}
        
        for img in result['data']:
            theme = img.get('theme', 'unknown')
            emotion = img.get('emotion_tag', 'neutral')
            region = img.get('region', 'global')
            
            themes[theme] = themes.get(theme, 0) + 1
            emotions[emotion] = emotions.get(emotion, 0) + 1
            regions[region] = regions.get(region, 0) + 1
        
        print(f"    ä¸»é¡Œ: {dict(themes)}")
        print(f"    æƒ…ç·’: {dict(emotions)}")
        print(f"    åœ°å€: {dict(regions)}")
    else:
        print(f"  âŒ å¤±æ•—: {response.status_code} - {response.text}")

if __name__ == "__main__":
    print("\nğŸŒŸ å¤šæ„Ÿå®˜æ²‰æµ¸å¼é–±è®€å™¨ - å…¨é¢æ¸¬è©¦")
    print("=" * 60)
    
    try:
        test_emotion_detection()
        test_complete_generation()
        test_tts()
        test_device_broadcast()
        test_rag_images()
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")
        print("="*60)
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. åœ¨ç€è¦½å™¨æ‰“é–‹: http://localhost:8010/web/multisensory_reader.html")
        print("  2. ä¾åºæ“ä½œ: å•Ÿå‹•é¡é ­ â†’ æª¢æ¸¬æƒ…ç·’ â†’ é€£æ¥è¨­å‚™ â†’ ç”Ÿæˆå…§å®¹")
        print("  3. è§€å¯Ÿè¡¨æƒ…åµæ¸¬æ•¸å€¼æ˜¯å¦å‹•æ…‹è®ŠåŒ–")
        print("  4. æª¢æŸ¥åœ–ç‰‡æ˜¯å¦èƒ½æ­£ç¢ºé¡¯ç¤º")
        print("  5. æ¸¬è©¦ä¸»é¡Œæ¨è–¦æ˜¯å¦æ ¹æ“šæƒ…ç·’èª¿æ•´")
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
