"""
Voice Engine - TTS (Text-to-Speech) & STT (Speech-to-Text)
æ”¯æ´å¤šç¨®èªéŸ³å¼•æ“ï¼šOpenAI, ElevenLabs, Google, Azure
"""

import os
import json
import time
import base64
from typing import Optional, Dict, Any, List
import requests
from pathlib import Path


class TTSEngine:
    """æ–‡å­—è½‰èªéŸ³å¼•æ“"""
    
    def __init__(
        self, 
        provider: str = "openai",
        api_key: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– TTS å¼•æ“
        
        Args:
            provider: èªéŸ³æä¾›å•† (openai, elevenlabs, google, azure)
            api_key: API é‡‘é‘°
        """
        self.provider = provider
        self.api_key = api_key or self._get_api_key(provider)
        
    def _get_api_key(self, provider: str) -> str:
        """å¾ç’°å¢ƒè®Šæ•¸ç²å– API Key"""
        key_map = {
            "openai": "OPENAI_API_KEY",
            "elevenlabs": "ELEVENLABS_API_KEY",
            "google": "GOOGLE_CLOUD_API_KEY",
            "azure": "AZURE_SPEECH_KEY"
        }
        return os.getenv(key_map.get(provider, ""), "")
    
    def text_to_speech(
        self, 
        text: str,
        voice: str = "alloy",
        emotion: Optional[str] = None,
        speed: float = 1.0,
        output_format: str = "mp3"
    ) -> Dict[str, Any]:
        """
        å°‡æ–‡å­—è½‰æ›ç‚ºèªéŸ³
        
        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            voice: èªéŸ³åç¨±
            emotion: æƒ…ç·’ï¼ˆå¦‚æœæ”¯æ´ï¼‰
            speed: èªé€Ÿ (0.5-2.0)
            output_format: è¼¸å‡ºæ ¼å¼ (mp3, wav, opus)
            
        Returns:
            {
                "audio_url": "https://...",
                "audio_base64": "...",
                "duration": 5.2,
                "format": "mp3"
            }
        """
        if self.provider == "openai":
            return self._openai_tts(text, voice, speed, output_format)
        elif self.provider == "elevenlabs":
            return self._elevenlabs_tts(text, voice, emotion, output_format)
        elif self.provider == "google":
            return self._google_tts(text, voice, speed, output_format)
        else:
            # å›å‚³æ¨¡æ“¬æ•¸æ“š
            return self._mock_tts(text, voice, speed, output_format)
    
    def _openai_tts(self, text: str, voice: str, speed: float, output_format: str) -> Dict:
        """ä½¿ç”¨ OpenAI TTS API"""
        if not self.api_key:
            return self._mock_tts(text, voice, speed, output_format)
        
        try:
            url = "https://api.openai.com/v1/audio/speech"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": "tts-1",
                "input": text,
                "voice": voice,  # alloy, echo, fable, onyx, nova, shimmer
                "speed": speed,
                "response_format": output_format
            }
            
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            
            # å„²å­˜éŸ³æª”
            audio_data = response.content
            filename = f"tts_{int(time.time())}.{output_format}"
            output_path = Path("static/audio") / filename
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, "wb") as f:
                f.write(audio_data)
            
            return {
                "audio_url": f"/static/audio/{filename}",
                "audio_base64": base64.b64encode(audio_data).decode('utf-8'),
                "duration": len(text) / 15.0,  # ä¼°ç®—
                "format": output_format,
                "provider": "openai",
                "voice": voice,
                "text": text
            }
            
        except Exception as e:
            print(f"OpenAI TTS éŒ¯èª¤: {e}")
            return self._mock_tts(text, voice, speed, output_format)
    
    def _elevenlabs_tts(self, text: str, voice: str, emotion: Optional[str], output_format: str) -> Dict:
        """ä½¿ç”¨ ElevenLabs TTS APIï¼ˆæ”¯æ´æƒ…ç·’ï¼‰"""
        if not self.api_key:
            return self._mock_tts(text, voice, 1.0, output_format)
        
        try:
            # ElevenLabs æ”¯æ´æƒ…ç·’é©…å‹•çš„èªéŸ³
            voice_id = voice or "21m00Tcm4TlvDq8ikWAM"  # Rachel é è¨­
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
            
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.api_key
            }
            
            # æ ¹æ“šæƒ…ç·’èª¿æ•´èªéŸ³åƒæ•¸
            emotion_settings = self._get_emotion_voice_settings(emotion)
            
            payload = {
                "text": text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": emotion_settings
            }
            
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            response.raise_for_status()
            
            audio_data = response.content
            filename = f"tts_elevenlabs_{int(time.time())}.{output_format}"
            output_path = Path("static/audio") / filename
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, "wb") as f:
                f.write(audio_data)
            
            return {
                "audio_url": f"/static/audio/{filename}",
                "audio_base64": base64.b64encode(audio_data).decode('utf-8'),
                "duration": len(text) / 15.0,
                "format": output_format,
                "provider": "elevenlabs",
                "voice": voice_id,
                "emotion": emotion,
                "text": text
            }
            
        except Exception as e:
            print(f"ElevenLabs TTS éŒ¯èª¤: {e}")
            return self._mock_tts(text, voice, 1.0, output_format)
    
    def _get_emotion_voice_settings(self, emotion: Optional[str]) -> Dict:
        """æ ¹æ“šæƒ…ç·’è¿”å›èªéŸ³è¨­å®š"""
        emotion_map = {
            "happy": {"stability": 0.3, "similarity_boost": 0.8, "style": 0.7},
            "sad": {"stability": 0.7, "similarity_boost": 0.6, "style": 0.3},
            "angry": {"stability": 0.4, "similarity_boost": 0.9, "style": 0.8},
            "fear": {"stability": 0.6, "similarity_boost": 0.7, "style": 0.4},
            "surprise": {"stability": 0.2, "similarity_boost": 0.8, "style": 0.9},
            "neutral": {"stability": 0.5, "similarity_boost": 0.75, "style": 0.5}
        }
        if not emotion or emotion not in emotion_map:
            return emotion_map["neutral"]
        return emotion_map[emotion]
    
    def _google_tts(self, text: str, voice: str, speed: float, output_format: str) -> Dict:
        """ä½¿ç”¨ Google Cloud TTS API"""
        # å¯¦ä½œé¡ä¼¼ OpenAIï¼Œé€™è£¡ç°¡åŒ–
        return self._mock_tts(text, voice, speed, output_format)
    
    def _mock_tts(self, text: str, voice: str, speed: float, output_format: str) -> Dict:
        """æ¨¡æ“¬ TTS è¼¸å‡º"""
        return {
            "audio_url": f"/static/audio/mock_tts_{int(time.time())}.{output_format}",
            "audio_base64": "",
            "duration": len(text) / (15.0 * speed),
            "format": output_format,
            "provider": "mock",
            "voice": voice,
            "text": text,
            "note": "æ¨¡æ“¬æ•¸æ“š - è«‹è¨­å®š API Key ä»¥ä½¿ç”¨çœŸå¯¦ TTS"
        }


class STTEngine:
    """èªéŸ³è½‰æ–‡å­—å¼•æ“"""
    
    def __init__(
        self, 
        provider: str = "openai",
        api_key: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– STT å¼•æ“
        
        Args:
            provider: èªéŸ³æä¾›å•† (openai, google, azure)
            api_key: API é‡‘é‘°
        """
        self.provider = provider
        self.api_key = api_key or self._get_api_key(provider)
    
    def _get_api_key(self, provider: str) -> str:
        """å¾ç’°å¢ƒè®Šæ•¸ç²å– API Key"""
        key_map = {
            "openai": "OPENAI_API_KEY",
            "google": "GOOGLE_CLOUD_API_KEY",
            "azure": "AZURE_SPEECH_KEY"
        }
        return os.getenv(key_map.get(provider, ""), "")
    
    def speech_to_text(
        self, 
        audio_data: bytes,
        language: str = "zh-TW",
        audio_format: str = "webm"
    ) -> Dict[str, Any]:
        """
        å°‡èªéŸ³è½‰æ›ç‚ºæ–‡å­—
        
        Args:
            audio_data: éŸ³è¨Šæ•¸æ“šï¼ˆbytesï¼‰
            language: èªè¨€ä»£ç¢¼
            audio_format: éŸ³è¨Šæ ¼å¼
            
        Returns:
            {
                "text": "è½‰æ›å¾Œçš„æ–‡å­—",
                "confidence": 0.95,
                "language": "zh-TW",
                "duration": 3.2
            }
        """
        if self.provider == "openai":
            return self._openai_stt(audio_data, language)
        elif self.provider == "google":
            return self._google_stt(audio_data, language)
        else:
            return self._mock_stt(audio_data, language)
    
    def _openai_stt(self, audio_data: bytes, language: str) -> Dict:
        """ä½¿ç”¨ OpenAI Whisper API"""
        if not self.api_key:
            return self._mock_stt(audio_data, language)
        
        try:
            url = "https://api.openai.com/v1/audio/transcriptions"
            headers = {
                "Authorization": f"Bearer {self.api_key}"
            }
            
            files = {
                "file": ("audio.webm", audio_data, "audio/webm")
            }
            data = {
                "model": "whisper-1",
                "language": language.split("-")[0]  # zh-TW -> zh
            }
            
            response = requests.post(url, headers=headers, files=files, data=data, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            
            return {
                "text": result.get("text", ""),
                "confidence": 0.95,  # Whisper ä¸è¿”å›ç½®ä¿¡åº¦
                "language": language,
                "duration": len(audio_data) / 16000,  # ä¼°ç®—
                "provider": "openai"
            }
            
        except Exception as e:
            print(f"OpenAI STT éŒ¯èª¤: {e}")
            return self._mock_stt(audio_data, language)
    
    def _google_stt(self, audio_data: bytes, language: str) -> Dict:
        """ä½¿ç”¨ Google Cloud Speech-to-Text API"""
        # å¯¦ä½œé¡ä¼¼ OpenAI
        return self._mock_stt(audio_data, language)
    
    def _mock_stt(self, audio_data: bytes, language: str) -> Dict:
        """æ¨¡æ“¬ STT è¼¸å‡º"""
        return {
            "text": "é€™æ˜¯æ¨¡æ“¬çš„èªéŸ³è½‰æ–‡å­—çµæœ",
            "confidence": 0.85,
            "language": language,
            "duration": len(audio_data) / 16000,
            "provider": "mock",
            "note": "æ¨¡æ“¬æ•¸æ“š - è«‹è¨­å®š API Key ä»¥ä½¿ç”¨çœŸå¯¦ STT"
        }


class VoiceController:
    """èªéŸ³æ§åˆ¶å™¨ - æ•´åˆ TTS å’Œ STT"""
    
    def __init__(self):
        self.tts_engine = TTSEngine()
        self.stt_engine = STTEngine()
    
    def speak(
        self, 
        text: str, 
        emotion: Optional[str] = None,
        voice: str = "alloy"
    ) -> Dict[str, Any]:
        """
        å°‡æ–‡å­—è½‰ç‚ºèªéŸ³ä¸¦æ’­æ”¾
        
        Args:
            text: è¦èªªçš„æ–‡å­—
            emotion: æƒ…ç·’ï¼ˆå½±éŸ¿èªèª¿ï¼‰
            voice: èªéŸ³åç¨±
        """
        return self.tts_engine.text_to_speech(
            text=text,
            voice=voice,
            emotion=emotion
        )
    
    def listen(self, audio_data: bytes) -> Dict[str, Any]:
        """
        è½å–èªéŸ³ä¸¦è½‰ç‚ºæ–‡å­—
        
        Args:
            audio_data: éŒ„éŸ³æ•¸æ“š
        """
        return self.stt_engine.speech_to_text(audio_data)
    
    def conversation_loop(
        self,
        user_audio: bytes,
        system_response_text: str,
        emotion: str = "neutral"
    ) -> Dict[str, Any]:
        """
        å®Œæ•´å°è©±å¾ªç’°ï¼šè½ â†’ è™•ç† â†’ èªª
        
        Args:
            user_audio: ç”¨æˆ¶èªéŸ³
            system_response_text: ç³»çµ±å›æ‡‰æ–‡å­—
            emotion: å›æ‡‰æƒ…ç·’
            
        Returns:
            {
                "user_text": "ç”¨æˆ¶èªªçš„è©±",
                "system_audio": "ç³»çµ±èªéŸ³",
                "emotion": "neutral"
            }
        """
        # 1. STT: è½å–ç”¨æˆ¶èªéŸ³
        stt_result = self.listen(user_audio)
        
        # 2. TTS: ç”Ÿæˆç³»çµ±å›æ‡‰èªéŸ³
        tts_result = self.speak(system_response_text, emotion)
        
        return {
            "user_text": stt_result["text"],
            "user_confidence": stt_result["confidence"],
            "system_text": system_response_text,
            "system_audio_url": tts_result["audio_url"],
            "system_audio_base64": tts_result["audio_base64"],
            "emotion": emotion,
            "timestamp": int(time.time())
        }


# å…¨å±€å¯¦ä¾‹
voice_controller = VoiceController()


if __name__ == "__main__":
    # æ¸¬è©¦ TTS
    controller = VoiceController()
    
    print("ğŸ¤ æ¸¬è©¦ TTS (æ–‡å­—è½‰èªéŸ³)")
    result = controller.speak(
        text="ä½ å¥½ï¼é€™æ˜¯ä¸€å€‹æ¸¬è©¦è¨Šæ¯ã€‚ä»Šå¤©å¤©æ°£çœŸå¥½ï¼",
        emotion="happy",
        voice="alloy"
    )
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\nğŸ”Š æ¸¬è©¦ STT (èªéŸ³è½‰æ–‡å­—)")
    # æ¨¡æ“¬éŸ³è¨Šæ•¸æ“š
    mock_audio = b"mock_audio_data"
    result = controller.listen(mock_audio)
    print(json.dumps(result, indent=2, ensure_ascii=False))
