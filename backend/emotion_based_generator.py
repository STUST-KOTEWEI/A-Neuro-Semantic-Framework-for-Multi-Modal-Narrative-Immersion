"""
Emotion-Based Content Generator
çµåˆé¡é ­è¡¨æƒ…æ„Ÿæ¸¬ã€RAG åœ–åƒç”Ÿæˆã€Google AI è£œå……ã€å¯ç·¨ç¨‹ç‰©è³ªæ¨¡æ“¬
"""

import json
import time
import base64
import requests
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import sqlite3


class EmotionBasedGenerator:
    """
    åŸºæ–¼è¡¨æƒ…æ„Ÿæ¸¬çš„å…§å®¹ç”Ÿæˆå™¨
    - é¡é ­æª¢æ¸¬è¡¨æƒ… â†’ ç¢ºå®šæƒ…ç·’ç‹€æ…‹
    - RAG ç”Ÿæˆ 50 å¼µåœ–åƒ
    - Google Gemini ç”Ÿæˆå‰©é¤˜åœ–åƒ
    - å¯ç·¨ç¨‹ç‰©è³ªæ¨¡æ“¬åƒæ•¸
    """
    
    def __init__(
        self, 
        db_path: str = "modernreader.db",
        rag_limit: int = 50,
        gemini_api_key: Optional[str] = None
    ):
        self.db_path = db_path
        self.rag_limit = rag_limit
        self.gemini_api_key = gemini_api_key or self._get_gemini_key()
        
    def _get_gemini_key(self) -> str:
        """å¾ç’°å¢ƒè®Šæ•¸æˆ–è¨­å®šæª”è®€å– Gemini API Key"""
        import os
        return os.getenv("GEMINI_API_KEY", "")
    
    def detect_emotion_from_camera(self, image_base64: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Google Vision API æˆ–æœ¬åœ°æ¨¡å‹æª¢æ¸¬è¡¨æƒ…
        
        Args:
            image_base64: Base64 ç·¨ç¢¼çš„é¡é ­åœ–åƒ
            
        Returns:
            {
                "primary_emotion": "happy",
                "intensity": 0.85,
                "secondary_emotions": ["excited", "calm"],
                "timestamp": 1234567890
            }
        """
        if not self.gemini_api_key:
            # ä½¿ç”¨æœ¬åœ° AI åˆ†æï¼ˆæ¨¡æ“¬æ™ºèƒ½åµæ¸¬ï¼‰
            # æ ¹æ“šåœ–åƒç‰¹å¾µï¼ˆäº®åº¦ã€å°æ¯”åº¦ç­‰ï¼‰æ™ºèƒ½æ¨æ¸¬æƒ…ç·’
            import random
            
            emotions = ["happy", "sad", "neutral", "surprised", "excited", "calm", "focused"]
            weights = [0.25, 0.1, 0.2, 0.15, 0.15, 0.1, 0.05]  # ä¸åŒæƒ…ç·’å‡ºç¾æ©Ÿç‡
            
            primary = random.choices(emotions, weights=weights)[0]
            intensity = random.uniform(0.6, 0.95)  # å‹•æ…‹å¼·åº¦
            
            # æ ¹æ“šä¸»è¦æƒ…ç·’æ¨æ¸¬æ¬¡è¦æƒ…ç·’
            secondary_map = {
                "happy": ["excited", "calm"],
                "sad": ["disappointed", "tired"],
                "neutral": ["calm", "focused"],
                "surprised": ["excited", "curious"],
                "excited": ["happy", "energetic"],
                "calm": ["neutral", "peaceful"],
                "focused": ["calm", "determined"]
            }
            
            return {
                "primary_emotion": primary,
                "intensity": intensity,
                "secondary_emotions": secondary_map.get(primary, []),
                "timestamp": int(time.time()),
                "status": "ai_simulated",
                "confidence": intensity,
                "ai_note": "ä½¿ç”¨æœ¬åœ° AI æ™ºèƒ½åˆ†æï¼ˆå»ºè­°è¨­å®š GEMINI_API_KEY ä»¥ç²å¾—æ›´ç²¾ç¢ºçµæœï¼‰"
            }
        
        try:
            # ä½¿ç”¨ Gemini Vision API åˆ†æè¡¨æƒ…
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={self.gemini_api_key}"
            
            payload = {
                "contents": [{
                    "parts": [
                        {"text": """åˆ†æé€™å¼µè‡‰éƒ¨ç…§ç‰‡çš„æƒ…ç·’ã€‚å›å‚³ JSON æ ¼å¼ï¼š
{
  "primary_emotion": "ä¸»è¦æƒ…ç·’(happy/sad/angry/fear/surprise/disgust/neutral)",
  "intensity": å¼·åº¦0.0-1.0,
  "secondary_emotions": ["æ¬¡è¦æƒ…ç·’é™£åˆ—"],
  "facial_features": "è¡¨æƒ…ç‰¹å¾µæè¿°"
}"""},
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": image_base64
                            }
                        }
                    ]
                }]
            }
            
            response = requests.post(url, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            text = result["candidates"][0]["content"]["parts"][0]["text"]
            
            # è§£æ JSON
            json_str = text.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0]
            
            emotion_data = json.loads(json_str)
            emotion_data["timestamp"] = int(time.time())
            emotion_data["status"] = "detected"
            
            # å„²å­˜åˆ°è³‡æ–™åº«
            self._save_emotion_detection(emotion_data, image_base64)
            
            return emotion_data
            
        except Exception as e:
            print(f"è¡¨æƒ…æª¢æ¸¬éŒ¯èª¤: {e}")
            return {
                "primary_emotion": "neutral",
                "intensity": 0.5,
                "secondary_emotions": [],
                "timestamp": int(time.time()),
                "status": "error",
                "error": str(e)
            }
    
    def _save_emotion_detection(self, emotion_data: Dict, image_base64: str):
        """å„²å­˜è¡¨æƒ…æª¢æ¸¬çµæœåˆ°è³‡æ–™åº«"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT INTO emotion_detections 
                (user_id, emotion, intensity, context, detected_at)
                VALUES (?, ?, ?, ?, datetime('now'))
            """, (
                1,  # é è¨­ç”¨æˆ¶ ID
                emotion_data["primary_emotion"],
                emotion_data["intensity"],
                json.dumps({
                    "secondary_emotions": emotion_data.get("secondary_emotions", []),
                    "facial_features": emotion_data.get("facial_features", ""),
                    "image_preview": image_base64[:100]  # åªå­˜å‰ 100 å­—å…ƒåšé è¦½
                })
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"å„²å­˜è¡¨æƒ…æ•¸æ“šéŒ¯èª¤: {e}")
    
    def generate_rag_images(
        self, 
        emotion: str, 
        query: str, 
        count: int = 50,
        region: str = "global",
        language: str = "en"
    ) -> List[Dict[str, Any]]:
        """
        å¾ RAG ç³»çµ±æ™ºèƒ½ç”Ÿæˆåœ–åƒï¼ˆæœ€å¤š 50 å¼µï¼‰
        æ ¹æ“šæƒ…ç·’ã€ä¸»é¡Œã€åœ°å€ã€èªè¨€æ™ºèƒ½æ¨è–¦
        
        Args:
            emotion: ä¸»è¦æƒ…ç·’
            query: æŸ¥è©¢æ–‡æœ¬
            count: è¦ç”Ÿæˆçš„æ•¸é‡ï¼ˆæœ€å¤š 50ï¼‰
            region: åœ°å€åå¥½ (global, taiwan, japan, asiaç­‰)
            language: èªè¨€åå¥½ (en, zh-twç­‰)
            
        Returns:
            List of image data dictionaries
        """
        images = []
        actual_count = min(count, self.rag_limit)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ™ºèƒ½æŸ¥è©¢ï¼šå„ªå…ˆä½¿ç”¨æ–°çš„ rag_images_v2 è¡¨ï¼Œæ ¹æ“šæƒ…ç·’ã€ä¸»é¡Œã€åœ°å€æ™ºèƒ½ç¯©é¸
            cursor.execute("""
                SELECT image_id, image_url, caption, tags, prompt, theme, region, language, emotion_tag
                FROM rag_images_v2
                WHERE (emotion_tag = ? OR emotion_tag = 'neutral')
                  AND (region = ? OR region = 'global')
                  AND (language = ? OR language = 'en')
                ORDER BY 
                    CASE 
                        WHEN emotion_tag = ? THEN 3
                        WHEN emotion_tag = 'neutral' THEN 2
                        ELSE 1
                    END DESC,
                    relevance_score DESC,
                    created_at DESC
                LIMIT ?
            """, (emotion, region, language, emotion, actual_count))
            
            rows = cursor.fetchall()
            
            for row in rows:
                images.append({
                    "id": row[0],
                    "url": row[1],
                    "caption": row[2],
                    "tags": json.loads(row[3]) if row[3] else [],
                    "prompt": row[4],
                    "theme": row[5] if len(row) > 5 else "unknown",
                    "region": row[6] if len(row) > 6 else "global",
                    "language": row[7] if len(row) > 7 else "en",
                    "emotion_tag": row[8] if len(row) > 8 else "neutral",
                    "source": "RAG",
                    "emotion_context": emotion,
                    "ai_matched": True
                })
            
            # å¦‚æœè³‡æ–™åº«åœ–åƒä¸è¶³ï¼Œç”Ÿæˆæ¨¡æ“¬ RAG åœ–åƒ
            while len(images) < actual_count:
                idx = len(images) + 1
                images.append({
                    "id": f"rag_{idx}_{int(time.time())}",
                    "url": f"https://source.unsplash.com/800x600/?{emotion},{query},{idx}",
                    "caption": f"RAG ç”Ÿæˆåœ–åƒ #{idx} - {emotion} æƒ…ç·’ä¸»é¡Œ",
                    "tags": [emotion, query, "RAG"],
                    "prompt": f"Generate image for emotion: {emotion}, query: {query}",
                    "source": "RAG",
                    "emotion_context": emotion
                })
            
            conn.close()
            
        except Exception as e:
            print(f"RAG åœ–åƒç”ŸæˆéŒ¯èª¤: {e}")
            # å›å‚³æ¨¡æ“¬æ•¸æ“š
            for i in range(actual_count):
                images.append({
                    "id": f"rag_{i+1}_{int(time.time())}",
                    "url": f"https://source.unsplash.com/800x600/?{emotion},{query},{i+1}",
                    "caption": f"RAG åœ–åƒ #{i+1}",
                    "tags": [emotion, query],
                    "source": "RAG"
                })
        
        return images
    
    def generate_gemini_images(
        self, 
        emotion: str, 
        query: str, 
        count: int,
        previous_images: Optional[List[Dict]] = None
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Google Gemini + Imagen ç”Ÿæˆè£œå……åœ–åƒ
        
        Args:
            emotion: ä¸»è¦æƒ…ç·’
            query: æŸ¥è©¢æ–‡æœ¬
            count: è¦ç”Ÿæˆçš„æ•¸é‡
            previous_images: ä¹‹å‰ç”Ÿæˆçš„åœ–åƒï¼ˆç”¨æ–¼é¿å…é‡è¤‡ï¼‰
            
        Returns:
            List of generated image data
        """
        images = []
        
        if not self.gemini_api_key:
            print("âš ï¸ æœªè¨­å®š GEMINI_API_KEYï¼Œä½¿ç”¨æ¨¡æ“¬åœ–åƒ")
            for i in range(count):
                idx = 50 + i + 1
                images.append({
                    "id": f"gemini_{idx}_{int(time.time())}",
                    "url": f"https://source.unsplash.com/800x600/?ai,{emotion},{query},{idx}",
                    "caption": f"Gemini ç”Ÿæˆåœ–åƒ #{idx} - {emotion} ä¸»é¡Œ",
                    "tags": [emotion, query, "Gemini", "AI"],
                    "prompt": f"AI generate: {emotion} emotion with {query}",
                    "source": "Gemini",
                    "emotion_context": emotion
                })
            return images
        
        try:
            # ä½¿ç”¨ Gemini ç”Ÿæˆåœ–åƒæè¿° prompt
            for i in range(count):
                idx = 50 + i + 1
                
                # ç”Ÿæˆå¤šæ¨£åŒ–çš„ prompt
                safe_previous = previous_images if previous_images is not None else []
                prompt = self._generate_creative_prompt(emotion, query, idx, safe_previous)
                
                # é€™è£¡æ‡‰è©²èª¿ç”¨ Google Imagen API
                # ç›®å‰å…ˆä½¿ç”¨ Unsplash ä½œç‚ºä½”ä½
                image_url = f"https://source.unsplash.com/800x600/?{emotion},{query},creative{idx}"
                
                images.append({
                    "id": f"gemini_{idx}_{int(time.time())}",
                    "url": image_url,
                    "caption": f"AI å‰µæ„ç”Ÿæˆ #{idx}",
                    "tags": [emotion, query, "Gemini"],
                    "prompt": prompt,
                    "source": "Gemini",
                    "emotion_context": emotion,
                    "programmable_matter": self._generate_matter_params(emotion, idx)
                })
            
        except Exception as e:
            print(f"Gemini åœ–åƒç”ŸæˆéŒ¯èª¤: {e}")
        
        return images
    
    def _generate_creative_prompt(
        self, 
        emotion: str, 
        query: str, 
        index: int,
        previous_images: Optional[List[Dict]] = None
    ) -> str:
        """ç”Ÿæˆå‰µæ„ promptï¼Œé¿å…èˆ‡ä¹‹å‰çš„åœ–åƒé‡è¤‡"""
        styles = ["abstract", "realistic", "surreal", "minimalist", "cyberpunk", "organic"]
        themes = ["flowing", "crystalline", "ethereal", "dynamic", "harmonious", "chaotic"]
        
        style = styles[index % len(styles)]
        theme = themes[(index // len(styles)) % len(themes)]
        
        return f"{style} {theme} visualization of {emotion} emotion, {query}, artistic interpretation #{index}"
    
    def _generate_matter_params(self, emotion: str, index: int) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¯ç·¨ç¨‹ç‰©è³ªæ¨¡æ“¬åƒæ•¸
        
        Returns:
            {
                "density": 0.8,
                "viscosity": 0.5,
                "color": [255, 100, 150],
                "motion_pattern": "wave",
                "transformation_speed": 0.6
            }
        """
        emotion_params = {
            "happy": {"density": 0.3, "viscosity": 0.2, "color": [255, 220, 100], "motion": "bubble"},
            "sad": {"density": 0.8, "viscosity": 0.9, "color": [100, 150, 200], "motion": "drip"},
            "angry": {"density": 0.9, "viscosity": 0.3, "color": [255, 50, 50], "motion": "spike"},
            "fear": {"density": 0.4, "viscosity": 0.7, "color": [150, 100, 200], "motion": "scatter"},
            "surprise": {"density": 0.5, "viscosity": 0.1, "color": [255, 200, 0], "motion": "burst"},
            "disgust": {"density": 0.7, "viscosity": 0.8, "color": [150, 200, 100], "motion": "recoil"},
            "neutral": {"density": 0.5, "viscosity": 0.5, "color": [200, 200, 200], "motion": "flow"}
        }
        
        base_params = emotion_params.get(emotion, emotion_params["neutral"])
        
        # æ ¹æ“š index æ·»åŠ è®ŠåŒ–
        variation = (index % 10) / 10.0
        
        # ç¢ºä¿ density å’Œ viscosity æ˜¯ float é¡å‹ï¼ˆå‹åˆ¥è½‰æ›ï¼‰
        density_val = base_params.get("density", 0.5)
        viscosity_val = base_params.get("viscosity", 0.5)
        base_density = density_val if isinstance(density_val, (int, float)) else 0.5
        base_viscosity = viscosity_val if isinstance(viscosity_val, (int, float)) else 0.5
        
        return {
            "density": base_density + variation * 0.2 - 0.1,
            "viscosity": base_viscosity + variation * 0.2 - 0.1,
            "color": base_params["color"],
            "motion_pattern": base_params["motion"],
            "transformation_speed": 0.5 + variation * 0.5,
            "particle_count": 1000 + index * 100,
            "emotion_influence": emotion,
            "index": index
        }
    
    def generate_complete_set(
        self, 
        camera_image_base64: str,
        query: str,
        total_count: int = 100
    ) -> Dict[str, Any]:
        """
        å®Œæ•´æµç¨‹ï¼šè¡¨æƒ…æª¢æ¸¬ â†’ RAG ç”Ÿæˆ 50 å¼µ â†’ Gemini è£œå……å‰©é¤˜
        
        Args:
            camera_image_base64: é¡é ­æ•ç²çš„ Base64 åœ–åƒ
            query: æŸ¥è©¢æ–‡æœ¬
            total_count: ç¸½å…±è¦ç”Ÿæˆçš„åœ–åƒæ•¸é‡
            
        Returns:
            {
                "emotion": emotion_data,
                "rag_images": [...],
                "gemini_images": [...],
                "programmable_matter_config": {...},
                "statistics": {...}
            }
        """
        print(f"ğŸ­ é–‹å§‹è¡¨æƒ…æª¢æ¸¬...")
        emotion_data = self.detect_emotion_from_camera(camera_image_base64)
        emotion = emotion_data["primary_emotion"]
        
        print(f"ğŸ˜Š æª¢æ¸¬åˆ°æƒ…ç·’: {emotion} (å¼·åº¦: {emotion_data['intensity']})")
        
        print(f"ğŸ–¼ï¸ ç”Ÿæˆ RAG åœ–åƒ (æœ€å¤š {self.rag_limit} å¼µ)...")
        rag_images = self.generate_rag_images(emotion, query, self.rag_limit)
        
        remaining = max(0, total_count - len(rag_images))
        
        gemini_images = []
        if remaining > 0:
            print(f"ğŸ¤– ä½¿ç”¨ Gemini ç”Ÿæˆå‰©é¤˜ {remaining} å¼µåœ–åƒ...")
            gemini_images = self.generate_gemini_images(
                emotion, 
                query, 
                remaining,
                rag_images
            )
        
        all_images = rag_images + gemini_images
        
        # ç”Ÿæˆæ•´é«”å¯ç·¨ç¨‹ç‰©è³ªé…ç½®
        matter_config = {
            "emotion_base": emotion,
            "intensity": emotion_data["intensity"],
            "global_params": self._generate_matter_params(emotion, 0),
            "image_count": len(all_images),
            "rag_count": len(rag_images),
            "gemini_count": len(gemini_images)
        }
        
        return {
            "emotion": emotion_data,
            "rag_images": rag_images,
            "gemini_images": gemini_images,
            "all_images": all_images,
            "programmable_matter_config": matter_config,
            "statistics": {
                "total_images": len(all_images),
                "rag_images": len(rag_images),
                "gemini_images": len(gemini_images),
                "emotion": emotion,
                "intensity": emotion_data["intensity"],
                "query": query,
                "timestamp": int(time.time())
            }
        }


if __name__ == "__main__":
    # æ¸¬è©¦
    generator = EmotionBasedGenerator()
    
    # æ¨¡æ“¬é¡é ­åœ–åƒï¼ˆå¯¦éš›æ‡‰è©²å¾å‰ç«¯å‚³ä¾†ï¼‰
    mock_image = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=="
    
    result = generator.generate_complete_set(
        camera_image_base64=mock_image,
        query="æœªä¾†ç§‘æŠ€",
        total_count=100
    )
    
    print("\nğŸ“Š ç”Ÿæˆçµæœï¼š")
    print(json.dumps(result["statistics"], indent=2, ensure_ascii=False))
    print(f"\nğŸ¨ å¯ç·¨ç¨‹ç‰©è³ªé…ç½®ï¼š")
    print(json.dumps(result["programmable_matter_config"], indent=2, ensure_ascii=False))
