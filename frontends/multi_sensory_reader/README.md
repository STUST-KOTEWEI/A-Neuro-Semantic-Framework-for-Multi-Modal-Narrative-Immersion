# 多感官閱讀器 (Multi-Sensory Reader)

## 專案使命

打造一款能識別書籍、感知使用者情緒，並透過多種感官輸出（語音、觸覺、嗅覺等）提供沉浸式閱讀體驗的跨平台應用程式。本專案旨在探索人機共感的可能性，並致力於知識的無障礙傳播。

## MVP 開發計畫

本計畫基於 Flutter 框架進行跨平台開發，並深度融合專案初始文件中的技術選型。

### 第一階段：建立基礎設施與核心內容整合

1.  **專案建立**:
    *   [x] 建立 `multi_sensory_reader` 資料夾。
    *   [x] 初始化 Flutter 專案。
2.  **內容來源整合**:
    *   **目標**: 接入指定的免費內容平台，建立應用的內容基礎。
    *   **實作**:
        *   整合 **Project Gutenberg** API，獲取免費電子書。
        *   整合 **Librivox** API，獲取免費有聲書。
        *   整合 **Forvo** API，實現單詞的真人發音功能，為方言及原住民語支援打下基礎。
3.  **實體書本辨識**:
    *   **目標**: 讓使用者可以透過掃描實體書快速將其加入數位書庫。
    *   **實作**:
        *   使用 `mobile_scanner` 套件實現 ISBN 條碼掃描。
        *   調用 **Google Books API** 根據 ISBN 獲取書本詳細資料（包括封面圖片）。

### 第二階段：整合先進的感官輸出入模組

1.  **語音合成 (TTS)**:
    *   **目標**: 提供高品質、富含情感的語音朗讀。
    *   **實作**:
        *   主力整合 **Eleven Labs** 的 API，實現富有表現力的情感語音合成。
        *   使用 `flutter_tts` 作為備用或離線的標準語音方案。
2.  **情緒辨識 (Affective Computing)**:
    *   **目標**: 辨識使用者情緒，為動態調整閱讀體驗提供依據。
    *   **實作**:
        *   **臉部表情**: 使用 `google_ml_kit` 進行臉部偵測，並載入一個預訓練的 TensorFlow Lite 情緒分類模型。
        *   **語音情緒**: 預留模型介面，為未來整合基於 CNN-LSTM 架構的語音情緒辨識模型做準備。
3.  **情感回饋循環 (Affective Loop v0.1)**:
    *   **目標**: 建立人機情感互動的初步閉環。
    *   **實作**: 將辨識出的情緒（如「悲傷」）作為參數，調用 Eleven Labs API 生成對應風格（如「輕柔」）的語音。

### 第三階段 (MVP 之後)：硬體與未來展望

根據專案文件的長遠規劃，在 MVP 成功後，我們將探索以下硬體整合：

*   **觸覺回饋**: 預留藍牙通訊介面，研發與 **bHaptics** 或 **Teslasuit** 的連動。
*   **嗅覺模擬**: 預留 API 介面，研究與 **Aromajoin** 裝置的整合。
*   **腦波感測**: 進行前沿探索，研究與消費級腦波感測裝置整合的可能性。